# Kolo

**Kolo** is a lightweight tool designed for **fast and efficient fine-tuning and testing of Large Language Models (LLMs)** on your local machine. It leverages cutting-edge tools to simplify the fine-tuning process, making it as quick and seamless as possible.

## ğŸš€ Features

- ğŸ— **Lightweight**: Minimal dependencies, optimized for speed.
- âš¡ **Runs Locally**: No need for cloud-based services; fine-tune models on your own machine.
- ğŸ›  **Easy Setup**: Simple installation and execution with Docker.
- ğŸ”Œ **Support for Popular Frameworks**: Integrates with major LLM toolkits.

## ğŸ›  Tools Used

Kolo is built using a powerful stack of LLM tools:

- [Unsloth](https://github.com/unslothai/unsloth) â€“ Efficient fine-tuning for LLMs.
- [Hugging Face](https://huggingface.co/) â€“ Model hosting, training, and deployment.
- [Llama.cpp](https://github.com/ggerganov/llama.cpp) â€“ Fast inference for Llama models.
- [Ollama](https://ollama.ai/) â€“ Simple and portable model management.
- [Docker](https://www.docker.com/) â€“ Containerized environment for easy deployment.
- [Open WebUI](https://github.com/open-webui/open-webui) â€“ Feature-rich and user-friendly self-hosted LLM web interface.

## ğŸƒ Getting Started

### 1ï¸âƒ£ Install Dependencies

Ensure [Docker](https://docs.docker.com/get-docker/) is installed on your system.

Ensure [WSL 2](https://learn.microsoft.com/en-us/windows/wsl/install) is installed on your windows machine.

### 2ï¸âƒ£ Build the Image

`./build.ps1`

### 3ï¸âƒ£ Run the Container

`./run.ps1`

### 4ï¸âƒ£ Connect via SSH

`./connect.ps1`

`password 123`

### 5ï¸âƒ£ Copy over your JSONL dataset

docker cp /path/to/local/file container_id:/path/in/container

...

### 6ï¸âƒ£ Train

Training

Save data into a Docker Volume so you do not lose it.
...

### 7ï¸âƒ£ Run

Ollama
and / or
openweb-ui
...

---

Discord group link
